---
title: "3 - Deeper into deployment"
subtitle: "Deploy and maintain models with vetiver"
format:
  revealjs: 
    slide-number: true
    footer: <https://posit-conf-2023.github.io/vetiver>
    preview-links: auto
    incremental: true
    theme: [default]
    width: 1280
    height: 720
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
---

```{r}
#| include: false
#| file: setup.R
```

## Plan for this workshop

::: nonincremental
-   *Versioning*
    -   Managing change in models âœ…
-   *Deploying*
    -   Putting models in REST APIs ðŸŽ¯
-   *Monitoring*
    -   Tracking model performance ðŸ‘€
:::

# Where does vetiver work?

::: nonincremental
-   Posit's pro products, like [Connect](https://posit.co/products/enterprise/connect/)

-   AWS SageMaker (R only, for now)

-   A public or private cloud, using Docker
:::


# {background-color="white" background-image="https://1000logos.net/wp-content/uploads/2021/11/Docker-Logo-1536x864.png" background-size="70%"}

# Docker

_Containerized environments for your code_

## Why Docker?

::: nonincremental
-   Open source
-   Reproducible
-   Bring your own container philosophy
:::

::: notes
ECR in AWS, etc
huggingface
:::

## Why Docker?

![](https://external-preview.redd.it/aR6WdUcsrEgld5xUlglgKX_0sC_NlryCPTXIHk5qdu8.jpg?auto=webp&s=5fe64dd318eec71711d87805d43def2765dd83cd){fig-align="center"}

## Create Docker artifacts

Start with a trained and versioned model

## Create Docker artifacts

::: nonincremental
-   Dockerfile
-   Model dependencies, typically `requirements.txt` or `renv.lock`
-   File to serve API, typically `app.py` or `plumber.R`
:::

### R

```{r}
#| eval: false
vetiver_prepare_docker(board, "isabel.zimmerman/inspection-results-r", port = 8080)
```

### Python

```{python}
#| eval: false
vetiver.prepare_docker(
    board, 
    "isabel.zimmerman/inspection-results-python",
    version = "20220901T144702Z-fd402",
    port = 8080
)
```

## Build your container

```bash
docker build -t inspection .
```

## Run your container

```bash
docker run --env-file .env -p 8080:8080 inspection
```

::: notes
probably .Renv if you are in R
:::

## Make predictions

### R

```{r}
#| eval: false
endpoint <- vetiver_endpoint("http://0.0.0.0:8080/predict")
predict(endpoint, X_test)
```

### Python

```{python}
#| eval: false
endpoint = vetiver.vetiver_endpoint("http://0.0.0.0:8080/predict")
vetiver.predict(endpoint=endpoint, data=X_test)
```

# Demo

## Docker resources

- [Enough Docker to be Dangerous](https://seankross.com/2017/09/17/Enough-Docker-to-be-Dangerous.html)
- [Python Docker](https://zetcode.com/python/docker/)
- [Ten simple rules for writing Dockerfiles for reproducible data science](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008316)
- [Docker info from Posit Solutions Engineering](https://solutions.posit.co/envs-pkgs/environments/docker/)

# Deploy preprocessors and models together

tktk more substantive feature engineering (like with learned transformation from training data)

## Deploy preprocessors and models together

![](images/good_workflow.png){fig-align="center"}


## What is wrong with this?

![](images/bad_workflow.png){fig-align="center"}

# Model metrics as metadata

tktk like https://vetiver.rstudio.com/learn-more/metrics-metadata.html

Transition to model monitoring at end

# Add a new endpoint to your API

